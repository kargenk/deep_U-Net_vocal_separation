{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import const as C\n",
    "import util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter = [kernel_height, kernel_width, input_channel, output_channel]\n",
    "# 畳み込み層(エンコーダ部分)\n",
    "def conv2d(x, output_channel, kernel=3, stride=2, batch_norm=True, is_training=True, leaky_relu=True):\n",
    "    net = tf.layers.conv2d(x,\n",
    "                          filters=output_channel,\n",
    "                          kernel_size=[kernel, kernel],\n",
    "                          strides=[stride, stride],\n",
    "                          padding='SAME')\n",
    "    if batch_norm:\n",
    "        net = tf.layers.batch_normalization(net, training=is_training)\n",
    "    if leaky_relu:\n",
    "        net = tf.nn.leaky_relu(net, 0.2)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter = [kernel_height, kernel_width, output_channel, input_channel]\n",
    "# output_shape = [バッチ数, 得たいheight, 得たいwidth, 得たいchannel]\n",
    "# 逆畳み込み層(デコーダ部分)\n",
    "def de_conv2d(x, output_channel, kernel=3, stride=2, batch_norm=True, is_training=True, relu=True):\n",
    "    net = tf.layers.conv2d_transpose(x,\n",
    "                                     filters=output_channel,\n",
    "                                     kernel_size=[kernel, kernel],\n",
    "                                     strides=[stride, stride],\n",
    "                                     padding='SAME')\n",
    "    if batch_norm:\n",
    "        net = tf.layers.batch_normalization(net, training=is_training)\n",
    "    if relu:\n",
    "        net = tf.nn.relu(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    net = {}\n",
    "    net['input'] = tf.Variable(np.zeros((1, C.IMAGE_HEIGHT, C.IMAGE_WIDTH, 1)).astype('float32'))\n",
    "    net['conv1'] = conv2d(net['input'], output_channel=16)\n",
    "    net['conv2'] = conv2d(net['conv1'], output_channel=32)\n",
    "    net['conv3'] = conv2d(net['conv2'], output_channel=64)\n",
    "    net['conv4'] = conv2d(net['conv3'], output_channel=128)\n",
    "    net['conv5'] = conv2d(net['conv4'], output_channel=256)\n",
    "    net['conv6'] = conv2d(net['conv5'], output_channel=512)\n",
    "    net['de_conv1'] = de_conv2d(net['conv6'], output_channel=256)\n",
    "    net['concat1'] = tf.concat([net['de_conv1'], net['conv5']], axis=-1)\n",
    "    net['dropout1'] = tf.nn.dropout(net['concat1'], rate=0.5)\n",
    "    net['de_conv2'] = de_conv2d(net['dropout1'], output_channel=128)\n",
    "    net['concat2'] = tf.concat([net['de_conv2'], net['conv4']], axis=-1)\n",
    "    net['dropout2'] = tf.nn.dropout(net['concat2'], rate=0.5)\n",
    "    net['de_conv3'] = de_conv2d(net['dropout2'], output_channel=64)\n",
    "    net['concat3'] = tf.concat([net['de_conv3'], net['conv3']], axis=-1)\n",
    "    net['dropout3'] = tf.nn.dropout(net['concat3'], rate=0.5)\n",
    "    net['de_conv4'] = de_conv2d(net['dropout3'], output_channel=32)\n",
    "    net['concat4'] = tf.concat([net['de_conv4'], net['conv2']], axis=-1)\n",
    "    net['de_conv5'] = de_conv2d(net['concat4'], output_channel=16)\n",
    "    net['concat5'] = tf.concat([net['de_conv5'], net['conv1']], axis=-1)\n",
    "    net['de_conv6'] = de_conv2d(net['concat5'], output_channel=1)\n",
    "    net['activation_final'] = tf.math.sigmoid(net['de_conv6'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-3012850f20f5>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-3012850f20f5>:10: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-0c2818d6d82c>:9: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "\n",
    "# 初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14767,\n",
       " 36074,\n",
       " 44315,\n",
       " 17906,\n",
       " 22335,\n",
       " 12657,\n",
       " 14785,\n",
       " 8583,\n",
       " 24003,\n",
       " 14940,\n",
       " 13220,\n",
       " 16860,\n",
       " 21937,\n",
       " 15111,\n",
       " 26031,\n",
       " 19254,\n",
       " 25409,\n",
       " 22191,\n",
       " 17338,\n",
       " 17623,\n",
       " 19209,\n",
       " 15664,\n",
       " 20808,\n",
       " 24412,\n",
       " 18837,\n",
       " 14642,\n",
       " 24541,\n",
       " 54140,\n",
       " 9821,\n",
       " 25668,\n",
       " 24351,\n",
       " 35549,\n",
       " 15000,\n",
       " 19737,\n",
       " 3181,\n",
       " 3133,\n",
       " 3169,\n",
       " 2993,\n",
       " 1504,\n",
       " 10748,\n",
       " 6524,\n",
       " 3606,\n",
       " 1710,\n",
       " 2478,\n",
       " 1505,\n",
       " 1128,\n",
       " 2236,\n",
       " 18346,\n",
       " 27306,\n",
       " 22070,\n",
       " 14979,\n",
       " 22640,\n",
       " 30621,\n",
       " 23704,\n",
       " 24933,\n",
       " 21005,\n",
       " 33763,\n",
       " 19652,\n",
       " 26154,\n",
       " 14385,\n",
       " 16266]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list, y_list = util.load_dataset(target=\"vocal\")\n",
    "item_length = [x.shape[1] for x in X_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "[14767, 36074, 44315, 17906, 22335, 12657, 14785, 8583, 24003, 14940, 13220, 16860, 21937, 15111, 26031, 19254, 25409, 22191, 17338, 17623, 19209, 15664, 20808, 24412, 18837, 14642, 24541, 54140, 9821, 25668, 24351, 35549, 15000, 19737, 3181, 3133, 3169, 2993, 1504, 10748, 6524, 3606, 1710, 2478, 1505, 1128, 2236, 18346, 27306, 22070, 14979, 22640, 30621, 23704, 24933, 21005, 33763, 19652, 26154, 14385, 16266]\n"
     ]
    }
   ],
   "source": [
    "print(len(item_length))\n",
    "print(item_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subepoch = sum(item_length) // C.PATCH_LENGTH // C.BATCH_SIZE * 4\n",
    "subepoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(object):\n",
    "    def __init__(self, batchsize=C.BATCH_SIZE, epoch=40, learning_rate=1e-4,\n",
    "                 dropout_rate=0.5, shuffle=True, random_seed=None):\n",
    "        np.random.seed(random_seed)\n",
    "        self.batchsize = batchsize\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            # 乱数シードを設定\n",
    "            tf.set_random_seed(random_seed)\n",
    "            # モデルを構築\n",
    "            self.build()\n",
    "            # 変数を初期化\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            # saver\n",
    "            self.saver = tf.train.Saver()\n",
    "        \n",
    "        # セッションを作成\n",
    "        self.sess = tf.Session(graph=g)\n",
    "    \n",
    "    def build(self):\n",
    "        net = {}\n",
    "        net['input'] = tf.Variable(np.zeros((1, C.IMAGE_HEIGHT, C.IMAGE_WIDTH, 1)).astype('float32'))\n",
    "        net['conv1'] = conv2d(net['input'], output_channel=16)\n",
    "        net['conv2'] = conv2d(net['conv1'], output_channel=32)\n",
    "        net['conv3'] = conv2d(net['conv2'], output_channel=64)\n",
    "        net['conv4'] = conv2d(net['conv3'], output_channel=128)\n",
    "        net['conv5'] = conv2d(net['conv4'], output_channel=256)\n",
    "        net['conv6'] = conv2d(net['conv5'], output_channel=512)\n",
    "        net['de_conv1'] = de_conv2d(net['conv6'], output_channel=256)\n",
    "        net['concat1'] = tf.concat([net['de_conv1'], net['conv5']], axis=-1)\n",
    "        net['dropout1'] = tf.nn.dropout(net['concat1'], rate=0.5)\n",
    "        net['de_conv2'] = de_conv2d(net['dropout1'], output_channel=128)\n",
    "        net['concat2'] = tf.concat([net['de_conv2'], net['conv4']], axis=-1)\n",
    "        net['dropout2'] = tf.nn.dropout(net['concat2'], rate=0.5)\n",
    "        net['de_conv3'] = de_conv2d(net['dropout2'], output_channel=64)\n",
    "        net['concat3'] = tf.concat([net['de_conv3'], net['conv3']], axis=-1)\n",
    "        net['dropout3'] = tf.nn.dropout(net['concat3'], rate=0.5)\n",
    "        net['de_conv4'] = de_conv2d(net['dropout3'], output_channel=32)\n",
    "        net['concat4'] = tf.concat([net['de_conv4'], net['conv2']], axis=-1)\n",
    "        net['de_conv5'] = de_conv2d(net['concat4'], output_channel=16)\n",
    "        net['concat5'] = tf.concat([net['de_conv5'], net['conv1']], axis=-1)\n",
    "        net['de_conv6'] = de_conv2d(net['concat5'], output_channel=1)\n",
    "        net['activation_final'] = tf.math.sigmoid(net['de_conv6'])\n",
    "        \n",
    "        # 損失関数\n",
    "        loss = tf.keras.metrics.mean_absolute_error(net['input']*net['activation_last'], y)\n",
    "        # 最適化\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        optimizer = optimizer.minimize(loss. name='train_op')\n",
    "        \n",
    "        def save(self, epoch, path='./tf-layers-model/'):\n",
    "            if not os.path.isdir(path):\n",
    "                os.makedirs(path)\n",
    "            \n",
    "            print('Saving model in %s' %path)\n",
    "            self.saver.save(self.sess,\n",
    "                            os.path.join(path, 'model.ckpt'),\n",
    "                            global_step=epoch)\n",
    "        \n",
    "        def load(self, epoch, path):\n",
    "            print('Loading model from %s' %path)\n",
    "            self.saver.restore(self.sess,\n",
    "                               os.path.join(path, 'model.ckpt-%d' % epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
