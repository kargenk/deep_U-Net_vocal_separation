{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import Chain, serializers, optimizers, config\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import const as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(Chain):\n",
    "    \"\"\"\n",
    "    Network Architecture of UNet, Core Class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(1, 16, 4, 2, 2)\n",
    "            self.norm1 = L.BatchNormalization(16)\n",
    "            self.conv2 = L.Convolution2D(16, 32, 4, 2, 2)\n",
    "            self.norm2 = L.BatchNormalization(32)\n",
    "            self.conv3 = L.Convolution2D(32, 64, 4, 2, 2)\n",
    "            self.norm3 = L.BatchNormalization(64)\n",
    "            self.conv4 = L.Convolution2D(64, 128, 4, 2, 2)\n",
    "            self.norm4 = L.BatchNormalization(128)\n",
    "            self.conv5 = L.Convolution2D(128, 256, 4, 2, 2)\n",
    "            self.norm5 = L.BatchNormalization(256)\n",
    "            self.conv6 = L.Convolution2D(256, 512, 4, 2, 2)\n",
    "            self.norm6 = L.BatchNormalization(512)\n",
    "            self.deconv1 = L.Deconvolution2D(512, 256, 4, 2, 2)\n",
    "            self.denorm1 = L.BatchNormalization(256)\n",
    "            self.deconv2 = L.Deconvolution2D(512, 128, 4, 2, 2)\n",
    "            self.denorm2 = L.BatchNormalization(128)\n",
    "            self.deconv3 = L.Deconvolution2D(256, 64, 4, 2, 2)\n",
    "            self.denorm3 = L.BatchNormalization(64)\n",
    "            self.deconv4 = L.Deconvolution2D(128, 32, 4, 2, 2)\n",
    "            self.denorm4 = L.BatchNormalization(32)\n",
    "            self.deconv5 = L.Deconvolution2D(64, 16, 4, 2, 2)\n",
    "            self.denorm5 = L.BatchNormalization(16)\n",
    "            self.deconv6 = L.Deconvolution2D(32, 1, 4, 2, 2)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        h1 = F.leaky_relu(self.norm1(self.conv1(X)))\n",
    "        h2 = F.leaky_relu(self.norm2(self.conv2(h1)))\n",
    "        h3 = F.leaky_relu(self.norm3(self.conv3(h2)))\n",
    "        h4 = F.leaky_relu(self.norm4(self.conv4(h3)))\n",
    "        h5 = F.leaky_relu(self.norm5(self.conv5(h4)))\n",
    "        h6 = F.leaky_relu(self.norm6(self.conv6(h5)))\n",
    "        dh = F.relu(F.dropout(self.denorm1(self.deconv1(h6))))\n",
    "        dh = F.relu(F.dropout(self.denorm2(self.deconv2(F.concat((dh, h5))))))\n",
    "        dh = F.relu(F.dropout(self.denorm3(self.deconv3(F.concat((dh, h4))))))\n",
    "        dh = F.relu(self.denorm4(self.deconv4(F.concat((dh, h3)))))\n",
    "        dh = F.relu(self.denorm5(self.deconv5(F.concat((dh, h2)))))\n",
    "        dh = F.sigmoid(self.deconv6(F.concat((dh, h1))))\n",
    "        return dh\n",
    "    \n",
    "    def load(self, file_name='unet.model'):\n",
    "        serializers.load_npz(file_name, self)\n",
    "    \n",
    "    def save(self, file_name='unet.model'):\n",
    "        serializers.save_npz(file_name, self)\n",
    "        \n",
    "class Trainer_UNet(Chain):\n",
    "    \"\"\"\n",
    "    cantain loss function for train Class\n",
    "    \"\"\"\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.unet = unet\n",
    "    \n",
    "    def __call__(self, X, y):\n",
    "        O = self.unet(X)  # UNetを通した後のマスク\n",
    "        self.loss = F.mean_absolute_error(X * O, Y)\n",
    "        return self.loss\n",
    "\n",
    "def train(X_list, y_list, epoch=40, save_file='unet.model'):\n",
    "    assert(len(X_list) == len(y_list))\n",
    "    \n",
    "    # 各種セッティングの有効化\n",
    "    model.to_gpu(0)\n",
    "    config.train = True\n",
    "    config.enable_backprop = True\n",
    "    \n",
    "    # モデルのインスタンス化\n",
    "    unet = UNet()\n",
    "    model = Trainer_UNet(unet)\n",
    "    optimizer = optimizers.Adam().set(model)  # オプティマイザのセッティング\n",
    "    \n",
    "    music_count = len(X_list)\n",
    "    music_length = [x.shape[1] for x in X_list]\n",
    "    sub_epoch = sum(music_length) // C.PATCH_LENGTH // C.BATCH_SIZE * 4\n",
    "    \n",
    "    for ep in range(epoch):\n",
    "        sum_loss = 0.0\n",
    "        for sub_ep in range(sub_epoch):\n",
    "            X = np.zeros((C.BATCH_SIZE, 1, 512, C.PATCH_LENGTH),\n",
    "                         dtype='float32')\n",
    "            y = np.zeros((C.BATCH_SIZE, 1, 512, C.PATCH_LENGTH),\n",
    "                         dtype='float32')\n",
    "            music_index = np.random.randint(0, music_count, C.BATCH_SIZE)\n",
    "            \n",
    "            for i in range(C.BATCH_SIZE):\n",
    "                rand_index = np.random.randint(\n",
    "                    music_length[music_index[i] - C.PATCH_LENGTH - 1])\n",
    "                X[i, 0, :, :] = \\\n",
    "                    X_list[music_index[i]][1:, music_index:music_index + C.PATCH_LENGTH]\n",
    "                y[i, 0, :, :] = \\\n",
    "                    y_list[music_index[i]][1:, music_index:music_index + C.PATCH_LENGTH]\n",
    "            \n",
    "            opt.update(model, cp.asarray(X), cp.asarray(y))\n",
    "            sum_loss += model.loss.data * C.BATCH_SIZE\n",
    "        \n",
    "        print('epoch: %d/%d  loss=%.3f' % (ep+1, epoch, sum_loss))\n",
    "    unet.save(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
