{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import const as C\n",
    "import util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nnのfilter = [kernel_height, kernel_width, input_channel, output_channel]\n",
    "# 畳み込み層(エンコーダ部分)\n",
    "def conv2d(x, output_channel, kernel=5, stride=2, pad='same', batch_norm=True, is_train=True, leaky_relu=True):\n",
    "    net = tf.layers.conv2d(x,\n",
    "                           filters=output_channel,\n",
    "                           kernel_size=[kernel, kernel],\n",
    "                           strides=[stride, stride],\n",
    "                           padding=pad)\n",
    "    if leaky_relu:\n",
    "        net = tf.nn.leaky_relu(net, 0.2)\n",
    "    if batch_norm:\n",
    "        net = tf.layers.batch_normalization(net, training=is_train)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nnのfilter = [kernel_height, kernel_width, output_channel, input_channel]\n",
    "# output_shape = [バッチ数, 得たいheight, 得たいwidth, 得たいchannel]\n",
    "# 逆畳み込み層(デコーダ部分)\n",
    "def de_conv2d(x, output_channel, kernel=5, stride=2, pad='same', batch_norm=True, is_train=True, relu=True):\n",
    "    net = tf.layers.conv2d_transpose(x,\n",
    "                                     filters=output_channel,\n",
    "                                     kernel_size=[kernel, kernel],\n",
    "                                     strides=[stride, stride],\n",
    "                                     padding=pad)\n",
    "    if relu:\n",
    "        net = tf.nn.relu(net)\n",
    "    if batch_norm:\n",
    "        net = tf.layers.batch_normalization(net, training=is_train)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ毎に処理する関数(ジェネレータを返す)\n",
    "def batch_generator(X, y, batch_size=C.BATCH_SIZE, shuffle=False, random_seed=None):\n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        rng.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "        \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i+batch_size, :], y[i:i+batch_size]) # 段階的に返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def UNet():\n",
    "#     net = {}\n",
    "#     net['input'] = tf.Variable(np.zeros((1, C.IMAGE_HEIGHT, C.IMAGE_WIDTH, 1)).astype('float32'))\n",
    "#     net['conv1'] = conv2d(net['input'], output_channel=16)\n",
    "#     net['conv2'] = conv2d(net['conv1'], output_channel=32)\n",
    "#     net['conv3'] = conv2d(net['conv2'], output_channel=64)\n",
    "#     net['conv4'] = conv2d(net['conv3'], output_channel=128)\n",
    "#     net['conv5'] = conv2d(net['conv4'], output_channel=256)\n",
    "#     net['conv6'] = conv2d(net['conv5'], output_channel=512)\n",
    "#     net['de_conv1'] = de_conv2d(net['conv6'], output_channel=256)\n",
    "#     net['concat1'] = tf.concat([net['de_conv1'], net['conv5']], axis=-1)\n",
    "#     net['dropout1'] = tf.nn.dropout(net['concat1'], rate=0.5)\n",
    "#     net['de_conv2'] = de_conv2d(net['dropout1'], output_channel=128)\n",
    "#     net['concat2'] = tf.concat([net['de_conv2'], net['conv4']], axis=-1)\n",
    "#     net['dropout2'] = tf.nn.dropout(net['concat2'], rate=0.5)\n",
    "#     net['de_conv3'] = de_conv2d(net['dropout2'], output_channel=64)\n",
    "#     net['concat3'] = tf.concat([net['de_conv3'], net['conv3']], axis=-1)\n",
    "#     net['dropout3'] = tf.nn.dropout(net['concat3'], rate=0.5)\n",
    "#     net['de_conv4'] = de_conv2d(net['dropout3'], output_channel=32)\n",
    "#     net['concat4'] = tf.concat([net['de_conv4'], net['conv2']], axis=-1)\n",
    "#     net['de_conv5'] = de_conv2d(net['concat4'], output_channel=16)\n",
    "#     net['concat5'] = tf.concat([net['de_conv5'], net['conv1']], axis=-1)\n",
    "#     net['de_conv6'] = de_conv2d(net['concat5'], output_channel=1)\n",
    "#     net['activation_final'] = tf.math.sigmoid(net['de_conv6'])\n",
    "#     return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-3012850f20f5>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-3012850f20f5>:10: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-0c2818d6d82c>:9: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    }
   ],
   "source": [
    "# model = UNet()\n",
    "\n",
    "# # 初期化\n",
    "# init = tf.global_variables_initializer()\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(object):\n",
    "    def __init__(self, batchsize=C.BATCH_SIZE, epochs=30, learning_rate=1e-4,\n",
    "                 dropout_rate=0.5, shuffle=True, random_seed=None):\n",
    "        np.random.seed(random_seed)\n",
    "        self.batchsize = batchsize\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            tf.set_random_seed(random_seed)\n",
    "            self.build()\n",
    "            self.init_op = tf.global_variables_initializer()  # 変数を初期化\n",
    "            self.saver = tf.train.Saver()\n",
    "        \n",
    "        # セッションを作成し，計算グラフgを渡す\n",
    "        self.sess = tf.Session(graph=g)\n",
    "    \n",
    "    def build(self):\n",
    "        is_train = tf.placeholder(tf.bool, shape=(), name='is_train')\n",
    "        tf_x = tf.placeholder(tf.float32, shape=[None, 512, 128, C.PATCH_LENGTH], name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.float32, shape=[None, 512, 128, C.PATCH_LENGTH], name='tf_y')\n",
    "        conv1 = conv2d(tf_x, output_channel=16)\n",
    "        conv2 = conv2d(conv1, output_channel=32)\n",
    "        conv3 = conv2d(conv2, output_channel=64)\n",
    "        conv4 = conv2d(conv3, output_channel=128)\n",
    "        conv5 = conv2d(conv4, output_channel=256)\n",
    "        conv6 = conv2d(conv5, output_channel=512)\n",
    "        de_conv1 = de_conv2d(conv6, output_channel=256)\n",
    "        concat1 = tf.concat([de_conv1, conv5], axis=-1)\n",
    "        dropout1 = tf.layers.dropout(concat1, rate=self.dropout_rate, training=is_train)\n",
    "        de_conv2 = de_conv2d(dropout1, output_channel=128)\n",
    "        concat2 = tf.concat([de_conv2, conv4], axis=-1)\n",
    "        dropout2 = tf.layers.dropout(concat2, rate=self.dropout_rate, training=is_train)\n",
    "        de_conv3 = de_conv2d(dropout2, output_channel=64)\n",
    "        concat3 = tf.concat([de_conv3, conv3], axis=-1)\n",
    "        dropout3 = tf.layers.dropout(concat3, rate=self.dropout_rate, training=is_train)\n",
    "        de_conv4 = de_conv2d(dropout3, output_channel=32)\n",
    "        concat4 = tf.concat([de_conv4, conv2], axis=-1)\n",
    "        de_conv5 = de_conv2d(concat4, output_channel=16)\n",
    "        concat5 = tf.concat([de_conv5, conv1], axis=-1)\n",
    "        de_conv6 = de_conv2d(concat5, output_channel=1, relu=False)\n",
    "        activation_final = tf.math.sigmoid(de_conv6)\n",
    "        \n",
    "        # 損失関数\n",
    "        pred = tf_x * activation_final  # マスクをかけた元音源\n",
    "        loss = tf.reduce_mean(\n",
    "                tf.map_fn(tf.abs, (pred - tf_y)),\n",
    "                name='mean_absolute_error')\n",
    "        # 最適化\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        optimizer = optimizer.minimize(loss, name='train_op')\n",
    "        \n",
    "        def save(self, epoch, path='./tf-layers-model/'):\n",
    "            if not os.path.isdir(path):\n",
    "                os.makedirs(path)\n",
    "            \n",
    "            print('Saving model in %s' % path)\n",
    "            self.saver.save(self.sess,\n",
    "                            os.path.join(path, 'model.ckpt'),\n",
    "                            global_step=epoch)\n",
    "        \n",
    "        def load(self, epoch, path):\n",
    "            print('Loading model from %s' % path)\n",
    "            self.saver.restore(self.sess,\n",
    "                               os.path.join(path, 'model.ckpt-%d' % epoch))\n",
    "            \n",
    "        def train(self, training_set, initialize=True, subepoch=None):\n",
    "            # 変数を初期化\n",
    "            if initialize:\n",
    "                self.sess.run(self.init_op)\n",
    "                \n",
    "            self.train_cost_ = []\n",
    "            X_data = np.array(training_set[0])\n",
    "            y_data = np.array(training_Set[1])\n",
    "            \n",
    "            for epoch in range(1, self.epoch + 1):\n",
    "                batch_gen = batch_generator(X_data, y_data, shuffle=self.shuffle)\n",
    "                avg_loss = 0.0\n",
    "                \n",
    "                for i in range(subepoch):\n",
    "                    for k, (batch_x, batch_y) in enumerate(batch_gen):\n",
    "                        feed = {'tf_x:0': batch_x,\n",
    "                                'tf_y:0': batch_y,\n",
    "                                'is_train:0': True} # ドロップアウト\n",
    "                        loss, _ = self.sess.run(['mean_absolute_error:0', 'train_op'],\n",
    "                                                feed_dict=feed)\n",
    "                        avg_loss += loss\n",
    "                    \n",
    "                print('Epoch %2d: Training Avg. Loss: %7.3f' % (epoch, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, y_list = util.load_dataset(target=\"vocal\")\n",
    "item_count = len(X_list)\n",
    "item_length = [x.shape[1] for x in X_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(X_list)\n",
    "print(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "[14767, 36074, 44315, 17906, 22335, 12657, 14785, 8583, 24003, 14940, 13220, 16860, 21937, 15111, 26031, 19254, 25409, 22191, 17338, 17623, 19209, 15664, 20808, 24412, 18837, 14642, 24541, 54140, 9821, 25668, 24351, 35549, 15000, 19737, 3181, 3133, 3169, 2993, 1504, 10748, 6524, 3606, 1710, 2478, 1505, 1128, 2236, 18346, 27306, 22070, 14979, 22640, 30621, 23704, 24933, 21005, 33763, 19652, 26154, 14385, 16266]\n"
     ]
    }
   ],
   "source": [
    "print(item_count)\n",
    "print(len(item_length))\n",
    "print(item_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subepoch = sum(item_length) // C.PATCH_LENGTH // C.BATCH_SIZE * 4\n",
    "print(subepoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(training_set=(X, y), subepoch=subepoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(epoch=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
